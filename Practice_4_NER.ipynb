{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ss9WR_zbQELO"
   },
   "source": [
    "# Practice 4: Named Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sB3vM2GfQELQ"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "### Formulation of the problem\n",
    "\n",
    "In this assignment, you will solve the Named Entity Recognition (NER) problem, one of the most common in NLP, along with the text classification problem.\n",
    "\n",
    "This task involves classifying each word/token whether it is part of a named entity (an entity may consist of multiple words/tokens) or not.\n",
    "\n",
    "For example, we want to extract names and organization names. Then for the text\n",
    "\n",
    "     Yan    Goodfellow  works  for  Google  Brain\n",
    "\n",
    "The model should extract the following sequence:\n",
    "\n",
    "     B-PER  I-PER       O      O    B-ORG   I-ORG\n",
    "\n",
    "where the prefixes *B-* and *I-* denote the beginning and end of the named entity, *O* denotes a word without a tag. This prefix system (*BIO* tagging) was introduced to distinguish between successive named entities of the same type.\n",
    "There are other types of tagging, such as [*BILUO*](https://en.wikipedia.org/wiki/Inside–outside–beginning_(tagging)), but for this tutorial we will focus on *BIO*.\n",
    "\n",
    "We will solve the NER problem on the CoNLL-2003 dataset using recurrent networks and models based on the Transformer architecture.\n",
    "\n",
    "### Libraries\n",
    "\n",
    "Main libraries:\n",
    "  - [PyTorch](https://pytorch.org/)\n",
    "  - [Transformers](https://github.com/huggingface/transformers)\n",
    "\n",
    "### Data\n",
    "\n",
    "The data is stored in an archive, which consists of:\n",
    "\n",
    "- *train.tsv* - training sample. Each line contains: <word / token>, <word / token tag>\n",
    "\n",
    "- *valid.tsv* - validation sample, which can be used to select hyperparameters and quality measurements. It has an identical structure to train.tsv.\n",
    "\n",
    "- *test.tsv* - test sample, which is used to evaluate the final quality. It has an identical structure to train.tsv.\n",
    "\n",
    "You can download the data here: [link](https://drive.google.com/drive/folders/1OKNrfHsBm1ehbG-yM0R1BGshbscf_eue?usp=drive_link)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "S5BCB1EfQan1",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:27.954240Z",
     "start_time": "2024-11-13T15:29:27.951463Z"
    }
   },
   "source": [
    "# !pip install numpy==1.21.6 scikit-learn==1.0.2 tensorboard==2.9.0 torch==1.12.1 tqdm==4.64.0 transformers==4.21.1"
   ],
   "outputs": [],
   "execution_count": 93
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Thidpb9qQELS",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:28.093522Z",
     "start_time": "2024-11-13T15:29:28.089867Z"
    }
   },
   "source": [
    "import random\n",
    "from collections import Counter, defaultdict, namedtuple\n",
    "from typing import Tuple, List, Dict, Any\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm, trange"
   ],
   "outputs": [],
   "execution_count": 94
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AiDlmbY2QELT"
   },
   "source": [
    "Let's fix the seed for reproducibility of the results (it is advisable to do this **always**!):"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yt3ISg3aQELU",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:28.217642Z",
     "start_time": "2024-11-13T15:29:28.211394Z"
    }
   },
   "source": [
    "def set_global_seed(seed: int) -> None:\n",
    "    \"\"\"\n",
    "    Set global seed for reproducibility.\n",
    "    \"\"\"\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "set_global_seed(42)"
   ],
   "outputs": [],
   "execution_count": 95
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AhIg0ZBzQELV"
   },
   "source": [
    "Let’s initialize the device (CPU / GPU) on which we will work (preferably **GPU**):"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rboLOv95QELV",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:28.372891Z",
     "start_time": "2024-11-13T15:29:28.368315Z"
    }
   },
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 96
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UW16ryFIQELW"
   },
   "source": [
    "Initialize *tensorboard* to log metrics during the training process:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6O7Y8hReTODp",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:28.580060Z",
     "start_time": "2024-11-13T15:29:28.570224Z"
    }
   },
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./logs/Practice_4_NER"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 1685183), started 1:43:15 ago. (Use '!kill 1685183' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1c80317fa3b1799d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 97
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4k3Nhd3IQELY"
   },
   "source": [
    "## Part 1. Data preparation (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4qYjOMuPQELY"
   },
   "source": [
    "First of all, we need to read the data. Let's write a function that takes as input the path to one of the conll-2003 files and returns two lists:\n",
    "- a list of lists of words/tokens (and corresponding to it)\n",
    "- list of lists of tags\n",
    "\n",
    "P.S. Let's make this function more flexible by supplying a boolean variable as input, whether we read data in *lowercase* or not.\n",
    "\n",
    "**Exercise. Implement the `read_conll2003` function.** **<font color='red'>(1 point)</font>**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wQdCfX2OQELZ",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:28.877276Z",
     "start_time": "2024-11-13T15:29:28.870445Z"
    }
   },
   "source": [
    "import csv\n",
    "\n",
    "def read_conll2003(\n",
    "    path: str,\n",
    "    lower: bool = True,\n",
    ") -> Tuple[List[List[str]], List[List[str]]]:\n",
    "    \"\"\"\n",
    "    Prepare data in CoNNL like format.\n",
    "    \"\"\"\n",
    "    \n",
    "    token_seq = []\n",
    "    label_seq = []\n",
    "\n",
    "    with open(path, \"r\", newline='\\n') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=\" \", quotechar=\"|\")\n",
    "        tok_seq = []\n",
    "        lab_seq = []\n",
    "        for row in reader:\n",
    "            if (len(row) == 0) and lower:\n",
    "                token_seq.append(tok_seq)\n",
    "                label_seq.append(lab_seq)\n",
    "                tok_seq = []\n",
    "                lab_seq = []\n",
    "                continue\n",
    "            if len(row) != 2:\n",
    "                print(len(row))\n",
    "                print(row)\n",
    "            tok_seq.append(row[0].lower() if lower else row[0])\n",
    "            lab_seq.append(row[1])\n",
    "\n",
    "    return token_seq, label_seq"
   ],
   "outputs": [],
   "execution_count": 98
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYm8xEvFQELb"
   },
   "source": [
    "Let's read all three files:\n",
    "\n",
    "- *train.tsv*\n",
    "- *valid.tsv*\n",
    "- *test.tsv*"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-inr1BPgQELb",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:29.338773Z",
     "start_time": "2024-11-13T15:29:29.038872Z"
    }
   },
   "source": [
    "train_token_seq, train_label_seq = read_conll2003(\"data/CoNLL-2003/train.tsv\")\n",
    "valid_token_seq, valid_label_seq = read_conll2003(\"data/CoNLL-2003/valid.tsv\")\n",
    "test_token_seq, test_label_seq = read_conll2003(\"data/CoNLL-2003/test.tsv\")"
   ],
   "outputs": [],
   "execution_count": 99
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sOoNc1VUQELc"
   },
   "source": [
    "Look at what we got:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HK8AcwWGQELd",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:29.474956Z",
     "start_time": "2024-11-13T15:29:29.471619Z"
    }
   },
   "source": [
    "for token, label in zip(train_token_seq[0], train_label_seq[0]):\n",
    "    print(f\"{token}\\t{label}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eu\tB-ORG\n",
      "rejects\tO\n",
      "german\tB-MISC\n",
      "call\tO\n",
      "to\tO\n",
      "boycott\tO\n",
      "british\tB-MISC\n",
      "lamb\tO\n",
      ".\tO\n"
     ]
    }
   ],
   "execution_count": 100
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "K8SqDeMJjF3Y",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:29.722347Z",
     "start_time": "2024-11-13T15:29:29.718213Z"
    }
   },
   "source": [
    "for token, label in zip(valid_token_seq[0], valid_label_seq[0]):\n",
    "    print(f\"{token}\\t{label}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cricket\tO\n",
      "-\tO\n",
      "leicestershire\tB-ORG\n",
      "take\tO\n",
      "over\tO\n",
      "at\tO\n",
      "top\tO\n",
      "after\tO\n",
      "innings\tO\n",
      "victory\tO\n",
      ".\tO\n"
     ]
    }
   ],
   "execution_count": 101
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ddFE7p5kjF_p",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:29.894769Z",
     "start_time": "2024-11-13T15:29:29.890651Z"
    }
   },
   "source": [
    "for token, label in zip(test_token_seq[0], test_label_seq[0]):\n",
    "    print(f\"{token}\\t{label}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soccer\tO\n",
      "-\tO\n",
      "japan\tB-LOC\n",
      "get\tO\n",
      "lucky\tO\n",
      "win\tO\n",
      ",\tO\n",
      "china\tB-PER\n",
      "in\tO\n",
      "surprise\tO\n",
      "defeat\tO\n",
      ".\tO\n"
     ]
    }
   ],
   "execution_count": 102
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BZ4Go3IXfDit",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:30.125062Z",
     "start_time": "2024-11-13T15:29:30.116883Z"
    }
   },
   "source": [
    "assert len(train_token_seq) == len(train_label_seq), \"The lengths of the training token_seq and label_seq do not match, an error in the read_conll2003 function\"\n",
    "assert len(valid_token_seq) == len(valid_label_seq), \"The lengths of the validation token_seq and label_seq do not match, an error in the read_conll2003 function\"\n",
    "assert len(test_token_seq) == len(test_label_seq), \"The lengths of the test token_seq and label_seq do not match, an error in the read_conll2003 function\"\n",
    "\n",
    "assert train_token_seq[0] == ['eu', 'rejects', 'german', 'call', 'to', 'boycott', 'british', 'lamb', '.'], \"Error in training token_seq\"\n",
    "assert train_label_seq[0] == ['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O'], \"Error in training label_seq\"\n",
    "\n",
    "assert valid_token_seq[0] == ['cricket', '-', 'leicestershire', 'take', 'over', 'at', 'top', 'after', 'innings', 'victory', '.'], \"Error in validation token_seq\"\n",
    "assert valid_label_seq[0] == ['O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], \"Error in validation label_seq\"\n",
    "\n",
    "assert test_token_seq[0] == ['soccer', '-', 'japan', 'get', 'lucky', 'win', ',', 'china', 'in', 'surprise', 'defeat', '.'], \"Error in test token_seq\"\n",
    "assert test_label_seq[0] == ['O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O'], \"Error in test label_seq\"\n",
    "\n",
    "print(\"All tests passed!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed!\n"
     ]
    }
   ],
   "execution_count": 103
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j96zKo6PQELd"
   },
   "source": [
    "The CoNLL-2003 dataset is presented in the form of **BIO** tagging, where the label is:\n",
    "- *B-{label}* - beginning of entity *{label}*\n",
    "- *I-{label}* - continuation of the entity *{label}*\n",
    "- *O* - no entity\n",
    "\n",
    "There are also other sequence tagging methods, such as **BILUO**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8SVL4USbQELe"
   },
   "source": [
    "### Preparing dictionaries\n",
    "\n",
    "To train the neural network, we will use two mappings:\n",
    "- {**token**}→{**token_idx**}: correspondence between word/token and string in *embedding* matrix (starts from 0);\n",
    "- {**label**}→{**label_idx**}: correspondence between tag and unique index (starts from 0);\n",
    "\n",
    "Now we need to implement two functions:\n",
    "- get_token2idx\n",
    "- get_label2idx\n",
    "\n",
    "which will return the corresponding dictionaries.\n",
    "\n",
    "P.S. token2idx dictionary must also contain special tokens:\n",
    "- `<PAD>` is a special token for padding, since we are going to train the models in batches\n",
    "- `<UNK>` is a special token for processing words/tokens that are not in the dictionary (relevant for inference)\n",
    "\n",
    "Let's assign them to idx 0 and 1 respectively for convenience.\n",
    "\n",
    "P.P.S. You can also add a *min_count* parameter to get_token2idx, which will only include words exceeding a certain frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOnc3UHpQELf"
   },
   "source": [
    "First let's collect:\n",
    "- token2cnt - a dictionary from a unique word / token to the number of these words / tokens in the training set (it is important that only in the training set!)\n",
    "- label_set - a list of unique tags\n",
    "\n",
    "P.S. You can also use stemming to convert different word forms of the same word into one token, but we will skip this point.\n",
    "\n",
    "**Exercise. Implement the `get_token2idx` and `get_label2idx` functions.** **<font color='red'>(1 point)</font>**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IthnXKsoo7A3",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:30.292588Z",
     "start_time": "2024-11-13T15:29:30.251404Z"
    }
   },
   "source": [
    "token2cnt = Counter([token for sentence in train_token_seq for token in sentence])"
   ],
   "outputs": [],
   "execution_count": 104
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "b_v8YUM7QELg",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:30.556262Z",
     "start_time": "2024-11-13T15:29:30.547545Z"
    }
   },
   "source": [
    "token2cnt.most_common(10)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 8390),\n",
       " ('.', 7374),\n",
       " (',', 7290),\n",
       " ('of', 3815),\n",
       " ('in', 3621),\n",
       " ('to', 3424),\n",
       " ('a', 3199),\n",
       " ('and', 2872),\n",
       " ('(', 2861),\n",
       " (')', 2861)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 105
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MSm7B546nmDh",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:30.913436Z",
     "start_time": "2024-11-13T15:29:30.905947Z"
    }
   },
   "source": [
    "print(f\"Number of unique words in the training dataset: {len(token2cnt)}\")\n",
    "print(f\"Number of words occurring only once in the training dataset: {len([token for token, cnt in token2cnt.items() if cnt == 1])}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in the training dataset: 21010\n",
      "Number of words occurring only once in the training dataset: 10060\n"
     ]
    }
   ],
   "execution_count": 106
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sRtCHt1QruSU"
   },
   "source": [
    "As we can see, we have many words that appear only once in the dataset. Obviously, we won’t be able to learn from them, we will only overfit, so let’s throw out such words when forming our vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aCaPftCyQELi",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:31.145823Z",
     "start_time": "2024-11-13T15:29:31.141047Z"
    }
   },
   "source": [
    "# use the min_count parameter to cut off words with frequency cnt < min_count\n",
    "\n",
    "def get_token2idx(\n",
    "    token2cnt: Dict[str, int],\n",
    "    min_count: int,\n",
    ") -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Get mapping from tokens to indices to use with Embedding layer.\n",
    "    \"\"\"\n",
    "    token2idx: Dict[str, int] = {}\n",
    "    token2idx[\"<PAD>\"] = 0\n",
    "    token2idx[\"<UNK>\"] = 1\n",
    "    idx = 2\n",
    "    for token, cnt in token2cnt.items():\n",
    "        if cnt < min_count:\n",
    "            continue\n",
    "        token2idx[token] = idx\n",
    "        idx += 1\n",
    "\n",
    "    return token2idx"
   ],
   "outputs": [],
   "execution_count": 107
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uFK130y-sLH4",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:31.289780Z",
     "start_time": "2024-11-13T15:29:31.282097Z"
    }
   },
   "source": [
    "token2idx = get_token2idx(token2cnt, min_count=2)"
   ],
   "outputs": [],
   "execution_count": 108
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "g69HFZC7QELh",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:31.441675Z",
     "start_time": "2024-11-13T15:29:31.422700Z"
    }
   },
   "source": [
    "# Function for sorting tags so that first there is an O tag,\n",
    "# then B- tags and only after I- tags (can be set manually)\n",
    "\n",
    "def sort_labels_func(x: str) -> int:\n",
    "    if x == \"O\":\n",
    "        return 0\n",
    "    elif x.startswith(\"B-\"):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "label_set = sorted(\n",
    "    set(label for sentence in train_label_seq for label in sentence),\n",
    "    key=lambda x: (sort_labels_func(x), x),\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 109
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VI_3m4qbQELi",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:31.594033Z",
     "start_time": "2024-11-13T15:29:31.589837Z"
    }
   },
   "source": [
    "label_set"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-LOC', 'B-MISC', 'B-ORG', 'B-PER', 'I-LOC', 'I-MISC', 'I-ORG', 'I-PER']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 110
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "t6i51GPtQELj",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:31.763658Z",
     "start_time": "2024-11-13T15:29:31.759322Z"
    }
   },
   "source": [
    "def get_label2idx(label_set: List[str]) -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Get mapping from labels to indices.\n",
    "    \"\"\"\n",
    "    \n",
    "    label2idx: Dict[str, int] = {}\n",
    "    idx = 0\n",
    "    for label in label_set:\n",
    "        label2idx[label] = idx\n",
    "        idx += 1\n",
    "    \n",
    "    return label2idx"
   ],
   "outputs": [],
   "execution_count": 111
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XW6fK0HtQELk",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:31.893345Z",
     "start_time": "2024-11-13T15:29:31.890288Z"
    }
   },
   "source": [
    "label2idx = get_label2idx(label_set)"
   ],
   "outputs": [],
   "execution_count": 112
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U13l-2IOQELk"
   },
   "source": [
    "Let's look at what we got:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "O7U7bMrHQELl",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:32.067383Z",
     "start_time": "2024-11-13T15:29:32.059863Z"
    }
   },
   "source": [
    "for token, idx in list(token2idx.items())[:10]:\n",
    "    print(f\"{token}\\t{idx}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PAD>\t0\n",
      "<UNK>\t1\n",
      "eu\t2\n",
      "german\t3\n",
      "call\t4\n",
      "to\t5\n",
      "boycott\t6\n",
      "british\t7\n",
      "lamb\t8\n",
      ".\t9\n"
     ]
    }
   ],
   "execution_count": 113
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Hp75V-o2QELl",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:32.311672Z",
     "start_time": "2024-11-13T15:29:32.307899Z"
    }
   },
   "source": [
    "for label, idx in label2idx.items():\n",
    "    print(f\"{label}\\t{idx}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O\t0\n",
      "B-LOC\t1\n",
      "B-MISC\t2\n",
      "B-ORG\t3\n",
      "B-PER\t4\n",
      "I-LOC\t5\n",
      "I-MISC\t6\n",
      "I-ORG\t7\n",
      "I-PER\t8\n"
     ]
    }
   ],
   "execution_count": 114
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VYb4BdAUhNzk",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:32.601730Z",
     "start_time": "2024-11-13T15:29:32.585438Z"
    }
   },
   "source": [
    "assert len(get_token2idx(token2cnt, min_count=1)) == 21012, \"Error in dictionary length, most likely min_count is implemented incorrectly\"\n",
    "assert len(token2idx) == 10952, \"Incorrect token2idx length, most likely min_count is implemented incorrectly\"\n",
    "assert len(label2idx) == 9, \"Incorrect label2idx length\"\n",
    "\n",
    "assert list(token2idx.items())[:10] == [\n",
    "    ('<PAD>', 0), ('<UNK>', 1), ('eu', 2), ('german', 3), ('call', 4),\n",
    "    ('to', 5), ('boycott', 6), ('british', 7), ('lamb', 8), ('.', 9)\n",
    "], \"Wrong format of token2idx\"\n",
    "assert label2idx == {\n",
    "    'O': 0, 'B-LOC': 1, 'B-MISC': 2, 'B-ORG': 3, 'B-PER': 4,\n",
    "    'I-LOC': 5, 'I-MISC': 6, 'I-ORG': 7, 'I-PER': 8\n",
    "}, \"Wrong format of label2idx\"\n",
    "\n",
    "print(\"All tests passed!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed!\n"
     ]
    }
   ],
   "execution_count": 115
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ItPs1DmOQELm"
   },
   "source": [
    "### Preparing the dataset and loader\n",
    "\n",
    "Typically, neural networks are trained in batches. This means that each update of the neural network's weights occurs based on multiple sequences. A technical detail is the need to complete all sequences within the batch to the same length.\n",
    "\n",
    "From the previous practical task, you should know about `Dataset` (`torch.utils.data.Dataset`) - a data structure that stores and can index data for training. The dataset must inherit from the standard PyTorch Dataset class and override the `__len__` and `__getitem__` methods.\n",
    "\n",
    "The `__getitem__` method must return the indexed sequence and its tags.\n",
    "\n",
    "**Don't forget** about `<UNK>` special token for unknown words!\n",
    "\n",
    "Let's write a custom dataset for our task, which will receive as input (the `__init__` method):\n",
    "- token_seq - list of lists of words/tokens\n",
    "- label_seq - list of lists of tags\n",
    "- token2idx\n",
    "- label2idx\n",
    "\n",
    "and return from the `__getitem__` method two int64 tensors (`torch.LongTensor`) with the indices of words / tokens in the sample and the indices of the corresponding tags:\n",
    "\n",
    "**Exercise. Implement the NERDataset class.** **<font color='red'>(1 point)</font>**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kdZvnUUpQELm",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:32.751894Z",
     "start_time": "2024-11-13T15:29:32.743014Z"
    }
   },
   "source": [
    "class NERDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for NER.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        token_seq: List[List[str]],\n",
    "        label_seq: List[List[str]],\n",
    "        token2idx: Dict[str, int],\n",
    "        label2idx: Dict[str, int],\n",
    "    ):\n",
    "        self.token2idx = token2idx\n",
    "        self.label2idx = label2idx\n",
    "\n",
    "        self.token_seq = [self.process_tokens(tokens, token2idx) for tokens in token_seq]\n",
    "        self.label_seq = [self.process_labels(labels, label2idx) for labels in label_seq]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.token_seq)\n",
    "\n",
    "    def __getitem__(\n",
    "        self,\n",
    "        idx: int,\n",
    "    ) -> Tuple[torch.LongTensor, torch.LongTensor]:\n",
    "        return torch.LongTensor(self.token_seq[idx]), torch.LongTensor(self.label_seq[idx])\n",
    "\n",
    "    @staticmethod\n",
    "    def process_tokens(\n",
    "        tokens: List[str],\n",
    "        token2idx: Dict[str, int],\n",
    "        unk: str = \"<UNK>\",\n",
    "    ) -> List[int]:\n",
    "        \"\"\"\n",
    "        Transform list of tokens into list of tokens' indices.\n",
    "        \"\"\"\n",
    "        processed_tokens = []\n",
    "        for token in tokens:\n",
    "            processed_tokens.append(token2idx[unk] if token not in token2idx else token2idx[token])\n",
    "        return processed_tokens\n",
    "\n",
    "    @staticmethod\n",
    "    def process_labels(\n",
    "        labels: List[str],\n",
    "        label2idx: Dict[str, int],\n",
    "    ) -> List[int]:\n",
    "        \"\"\"\n",
    "        Transform list of labels into list of labels' indices.\n",
    "        \"\"\"\n",
    "        processed_labels = []\n",
    "        for label in labels:\n",
    "            processed_labels.append(label2idx[label])\n",
    "        return processed_labels"
   ],
   "outputs": [],
   "execution_count": 116
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yCvaPJERQELn"
   },
   "source": [
    "Create three datasets:\n",
    "- *train_dataset*\n",
    "- *valid_dataset*\n",
    "- *test_dataset*"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bUMsSNkoQELn",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:32.972935Z",
     "start_time": "2024-11-13T15:29:32.841616Z"
    }
   },
   "source": [
    "train_dataset = NERDataset(\n",
    "    token_seq=train_token_seq,\n",
    "    label_seq=train_label_seq,\n",
    "    token2idx=token2idx,\n",
    "    label2idx=label2idx,\n",
    ")\n",
    "valid_dataset = NERDataset(\n",
    "    token_seq=valid_token_seq,\n",
    "    label_seq=valid_label_seq,\n",
    "    token2idx=token2idx,\n",
    "    label2idx=label2idx,\n",
    ")\n",
    "test_dataset = NERDataset(\n",
    "    token_seq=test_token_seq,\n",
    "    label_seq=test_label_seq,\n",
    "    token2idx=token2idx,\n",
    "    label2idx=label2idx,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 117
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jQIq1pAWQELo"
   },
   "source": [
    "Let's look at what we got:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Q_Scync0QELo",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:33.154017Z",
     "start_time": "2024-11-13T15:29:33.150025Z"
    }
   },
   "source": "train_dataset[0]",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2, 1, 3, 4, 5, 6, 7, 8, 9]), tensor([3, 0, 2, 0, 0, 0, 2, 0, 0]))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 118
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zyAazaLzjQ-K",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:33.396939Z",
     "start_time": "2024-11-13T15:29:33.391346Z"
    }
   },
   "source": [
    "valid_dataset[0]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1737,  571, 1777,  197,  687,  145,  349,  111, 1819, 1558,    9]),\n",
       " tensor([0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 119
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NHuuh3YmjRNt",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:33.589689Z",
     "start_time": "2024-11-13T15:29:33.584094Z"
    }
   },
   "source": [
    "test_dataset[0]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1516,  571, 1434, 1729, 4893, 2014,   67,  310,  215, 3157, 3139,    9]),\n",
       " tensor([0, 0, 1, 0, 0, 0, 0, 4, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 120
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Gox6uyF2idwZ",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:33.812196Z",
     "start_time": "2024-11-13T15:29:33.802278Z"
    }
   },
   "source": [
    "assert len(train_dataset) == 14986, \"Incorrect train_dataset length\"\n",
    "assert len(valid_dataset) == 3465, \"Incorrect valid_dataset length\"\n",
    "assert len(test_dataset) == 3683, \"Incorrect test_dataset length\"\n",
    "\n",
    "assert torch.equal(train_dataset[0][0], torch.tensor([2,1,3,4,5,6,7,8,9])), \"Malformed train_dataset\"\n",
    "assert torch.equal(train_dataset[0][1], torch.tensor([3,0,2,0,0,0,2,0,0])), \"Malformed train_dataset\"\n",
    "\n",
    "assert torch.equal(\n",
    "    valid_dataset[0][0],\n",
    "    torch.tensor([1737,571,1777,197,687,145,349,111,1819,1558,9])\n",
    "), \"Malformed valid_dataset\"\n",
    "assert torch.equal(valid_dataset[0][1], torch.tensor([0,0,3,0,0,0,0,0,0,0,0])), \"Malformed valid_dataset\"\n",
    "\n",
    "assert torch.equal(\n",
    "    test_dataset[0][0],\n",
    "    torch.tensor([1516,571,1434,1729,4893,2014,67,310,215,3157,3139,9])\n",
    "), \"Malformed test_dataset\"\n",
    "assert torch.equal(test_dataset[0][1], torch.tensor([0,0,1,0,0,0,0,4,0,0,0,0])), \"Malformed test_dataset\"\n",
    "\n",
    "print(\"All tests passed!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed!\n"
     ]
    }
   ],
   "execution_count": 121
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mWjJuAk7QELp"
   },
   "source": [
    "In order to complete sequences with padding, we will use the `collate_fn` parameter of the `DataLoader` class.\n",
    "\n",
    "Given a sequence of pairs of tensors for sentences and tags, it is necessary to complete all sequences to the sequence of the maximum length in the batch.\n",
    "\n",
    "Use the special token `<PAD>` for completion of word/token sequences and -1 for tag sequences.\n",
    "\n",
    "**hint**: it is convenient to use the `torch.nn.utils.rnn` method. Pay attention to the `batch_first` parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VZiJVM5qQELp"
   },
   "source": [
    "`Collator` can be implemented in two ways:\n",
    "- class with method `__call__`\n",
    "- function\n",
    "\n",
    "We will go the first way.\n",
    "\n",
    "Initialize an instance of the `Collator` class (the `__init__` method) using two parameters:\n",
    "- id `<PAD>` special token for word/token sequences\n",
    "- id `<PAD>` special token for tag sequences (value -1)\n",
    "\n",
    "The `__call__` method takes a batch as input, namely a list of tuples of what is returned from the `__getitem__` method of our dataset. In our case, this is a list of tuples of two int64 tensors - `List[Tuple[torch.LongTensor, torch.LongTensor]]`.\n",
    "\n",
    "Ad the output we want to get two tensors:\n",
    "- Indexes of word/token with paddings\n",
    "- Indexes of tags with paddings\n",
    "    \n",
    "P.S. The `<PAD>` value is needed to easily distinguish pad tokens from others when calculating loss. You can use the `ignore_index` parameter when initializing the loss.\n",
    "\n",
    "**Exercise. Implement the collator class NERCollator.** **<font color='red'>(1 point)</font>**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LNHNwoLnQELp",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:33.973449Z",
     "start_time": "2024-11-13T15:29:33.967466Z"
    }
   },
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "class NERCollator:\n",
    "    \"\"\"\n",
    "    Collator that handles variable-size sentences.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        token_padding_value: int,\n",
    "        label_padding_value: int,\n",
    "    ):\n",
    "        self.token_padding_value = token_padding_value\n",
    "        self.label_padding_value = label_padding_value\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        batch: List[Tuple[torch.LongTensor, torch.LongTensor]],\n",
    "    ) -> Tuple[torch.LongTensor, torch.LongTensor]:\n",
    "\n",
    "        tokens, labels = zip(*batch)\n",
    "        tokens = pad_sequence(tokens, batch_first=True, padding_value=self.token_padding_value)\n",
    "        labels = pad_sequence(labels, batch_first=True, padding_value=self.label_padding_value)\n",
    "        return tokens, labels\n",
    "        # tokens = list(tokens)\n",
    "        # labels = list(labels)\n",
    "        # \n",
    "        # max_tokens_length = max(map(len, tokens))\n",
    "        # max_labels_length = max(map(len, labels))\n",
    "        # \n",
    "        # for i in range(len(tokens)):\n",
    "        #     tokens[i] = torch.cat((tokens[i], torch.full((max_tokens_length - len(tokens[i]),), self.token_padding_value)))\n",
    "        # \n",
    "        # for i in range(len(labels)):\n",
    "        #     labels[i] = torch.cat((labels[i], torch.full((max_labels_length - len(labels[i]),), self.label_padding_value)))\n",
    "        # \n",
    "        # return torch.stack(tokens), torch.stack(labels)"
   ],
   "outputs": [],
   "execution_count": 122
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nZUMwVQTQELq",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:34.079970Z",
     "start_time": "2024-11-13T15:29:34.076772Z"
    }
   },
   "source": [
    "collator = NERCollator(\n",
    "    token_padding_value=token2idx[\"<PAD>\"],\n",
    "    label_padding_value=-1,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 123
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jsgfij8WQELq"
   },
   "source": [
    "Now everything is ready to define the loaders."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gFljkiBOQELr",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:34.218635Z",
     "start_time": "2024-11-13T15:29:34.212283Z"
    }
   },
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    collate_fn=collator,\n",
    ")\n",
    "valid_dataloader = torch.utils.data.DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=1,  # for correct metrics measurements leave batch_size=1\n",
    "    shuffle=False, # for correct metrics measurements leave shuffle=False\n",
    "    collate_fn=collator,\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,  # for correct metrics measurements leave batch_size=1\n",
    "    shuffle=False, # for correct metrics measurements leave shuffle=False\n",
    "    collate_fn=collator,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 124
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:34.386940Z",
     "start_time": "2024-11-13T15:29:34.381333Z"
    }
   },
   "cell_type": "code",
   "source": "torch.full((5,), 3)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 125
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i34wGJ4uQELr"
   },
   "source": [
    "Let's look at what we got:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QLlr_DztQELr",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:34.573443Z",
     "start_time": "2024-11-13T15:29:34.551338Z"
    }
   },
   "source": [
    "tokens, labels = next(iter(train_dataloader))\n",
    "\n",
    "tokens = tokens.to(device)\n",
    "labels = labels.to(device)"
   ],
   "outputs": [],
   "execution_count": 126
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FdMMEDdbQELs",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:34.728629Z",
     "start_time": "2024-11-13T15:29:34.723022Z"
    }
   },
   "source": [
    "tokens"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7796, 1162, 2553, 7237, 1342,    0,    0,    0,    0,    0],\n",
       "        [ 125, 1167,    1,   67, 1349,  489, 1215, 1364, 1365, 1366]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 127
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "w--fhADKQELs",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:35.168370Z",
     "start_time": "2024-11-13T15:29:35.164634Z"
    }
   },
   "source": [
    "labels"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3,  0,  3,  7,  0, -1, -1, -1, -1, -1],\n",
       "        [ 0,  4,  8,  0,  1,  0,  0,  0,  0,  0]], device='cuda:0')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 128
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yFeX0AYKlhGk",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:35.787939Z",
     "start_time": "2024-11-13T15:29:35.780038Z"
    }
   },
   "source": [
    "train_tokens, train_labels = next(iter(\n",
    "    torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=2,\n",
    "        shuffle=False,\n",
    "        collate_fn=collator,\n",
    "    )\n",
    "))\n",
    "assert torch.equal(\n",
    "    train_tokens,\n",
    "    torch.tensor([[2, 1, 3, 4, 5, 6, 7, 8, 9], [10, 11, 0, 0, 0, 0, 0, 0, 0]])\n",
    "), \"Looks like a bug in the collator\"\n",
    "assert torch.equal(\n",
    "    train_labels,\n",
    "    torch.tensor([[3, 0, 2, 0, 0, 0, 2, 0, 0], [4, 8, -1, -1, -1, -1, -1, -1, -1]])\n",
    "), \"Looks like a bug in the collator\"\n",
    "\n",
    "valid_tokens, valid_labels = next(iter(\n",
    "    torch.utils.data.DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=2,\n",
    "        shuffle=False,\n",
    "        collate_fn=collator,\n",
    "    )\n",
    "))\n",
    "assert torch.equal(\n",
    "    valid_tokens,\n",
    "    torch.tensor([\n",
    "        [1737, 571, 1777, 197, 687, 145, 349, 111,  1819, 1558, 9],\n",
    "        [248, 10679, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    ])), \"Looks like a bug in the collator\"\n",
    "assert torch.equal(\n",
    "    valid_labels,\n",
    "    torch.tensor([\n",
    "        [0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
    "    ])), \"Looks like a bug in the collator\"\n",
    "\n",
    "test_tokens, test_labels = next(iter(\n",
    "    torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=2,\n",
    "        shuffle=False,\n",
    "        collate_fn=collator,\n",
    "    )\n",
    "))\n",
    "assert torch.equal(\n",
    "    test_tokens,\n",
    "    torch.tensor([\n",
    "        [1516, 571, 1434, 1729, 4893, 2014, 67, 310, 215, 3157, 3139, 9],\n",
    "        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    ])), \"Looks like a bug in the collator\"\n",
    "assert torch.equal(\n",
    "    test_labels,\n",
    "    torch.tensor([\n",
    "        [0, 0, 1, 0, 0, 0, 0, 4, 0, 0, 0, 0],\n",
    "        [4, 8, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
    "    ])), \"Looks like a bug in the collator\"\n",
    "\n",
    "print(\"All tests passed!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed!\n"
     ]
    }
   ],
   "execution_count": 129
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Ul5gLriQELs"
   },
   "source": [
    "## Part 2. BiLSTM tagger (6 points)\n",
    "\n",
    "Define the network architecture using the PyTorch library.\n",
    "\n",
    "Your architecture at this point should follow the standard tagger:\n",
    "* Embedding layer at the input\n",
    "* LSTM (unidirectional or bidirectional) layer for sequence processing\n",
    "* Dropout (specified separately or built into LSTM) to reduce overfitting\n",
    "* Linear output layer\n",
    "\n",
    "To train the network, use an element-wise cross-entropy loss function.\n",
    "\n",
    "**Please note** that `<PAD>` tokens should not be included in the loss function calculation. It is recommended to use Adam as an optimizer. To obtain prediction values from model outputs, use the `argmax` function.\n",
    "\n",
    "**Exercise. Implement the BiLSTM model class.** **<font color='red'>(2 points)</font>**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uMiLQljZQELt",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:35.964878Z",
     "start_time": "2024-11-13T15:29:35.958245Z"
    }
   },
   "source": [
    "class BiLSTM(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Bidirectional LSTM architecture.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_embeddings: int,\n",
    "        embedding_dim: int,\n",
    "        hidden_size: int,\n",
    "        num_layers: int,\n",
    "        dropout: float,\n",
    "        bidirectional: bool,\n",
    "        n_classes: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = torch.nn.Embedding(num_embeddings=num_embeddings, embedding_dim=embedding_dim)\n",
    "        self.rnn = torch.nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout,\n",
    "            bidirectional=bidirectional,\n",
    "            batch_first=True\n",
    "        )  \n",
    "        self.head = torch.nn.Linear(hidden_size * 2 if bidirectional else hidden_size, n_classes)\n",
    "\n",
    "    def forward(self, tokens: torch.LongTensor) -> torch.Tensor:\n",
    "        embed = self.embedding(tokens)\n",
    "\n",
    "        # we use the special function pack_padded_sequence in order to obtain a PackedSequence structure\n",
    "        # that does not take padding into account when passing rnn\n",
    "        length = (tokens != 0).sum(dim=1).detach().cpu()\n",
    "        packed_embed = torch.nn.utils.rnn.pack_padded_sequence(\n",
    "            embed, length, batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "\n",
    "        # we use the special function pad_packed_sequence to get a tensor from PackedSequence\n",
    "        packed_rnn_output, _ = self.rnn(packed_embed)\n",
    "        rnn_output, _ = torch.nn.utils.rnn.pad_packed_sequence(\n",
    "            packed_rnn_output, batch_first=True\n",
    "        )\n",
    "\n",
    "        logits = self.head(rnn_output)\n",
    "        return logits.transpose(1, 2)"
   ],
   "outputs": [],
   "execution_count": 130
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zps8HL2VQELu",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:36.090205Z",
     "start_time": "2024-11-13T15:29:36.066947Z"
    }
   },
   "source": [
    "model = BiLSTM(\n",
    "    num_embeddings=len(token2idx),\n",
    "    embedding_dim=100,\n",
    "    hidden_size=100,\n",
    "    num_layers=1,\n",
    "    dropout=0.0,\n",
    "    bidirectional=True,\n",
    "    n_classes=len(label2idx),\n",
    ").to(device)"
   ],
   "outputs": [],
   "execution_count": 131
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nmg2_C_oQELu",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:36.262904Z",
     "start_time": "2024-11-13T15:29:36.258164Z"
    }
   },
   "source": [
    "model"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTM(\n",
       "  (embedding): Embedding(10952, 100)\n",
       "  (rnn): LSTM(100, 100, batch_first=True, bidirectional=True)\n",
       "  (head): Linear(in_features=200, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 132
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sDvWB5J2QELv",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:36.440428Z",
     "start_time": "2024-11-13T15:29:36.436622Z"
    }
   },
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=-1)"
   ],
   "outputs": [],
   "execution_count": 133
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Jn5Pu1UKQELv",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:36.558427Z",
     "start_time": "2024-11-13T15:29:36.552724Z"
    }
   },
   "source": "outputs = model(train_tokens.to(device))",
   "outputs": [],
   "execution_count": 134
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "n02Bsh8eQELw",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:36.744731Z",
     "start_time": "2024-11-13T15:29:36.739889Z"
    }
   },
   "source": [
    "assert outputs.shape == torch.Size([2, 9, 9])\n",
    "assert 2 < criterion(outputs, train_labels.to(device)) < 3\n",
    "\n",
    "print(\"All tests passed!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed!\n"
     ]
    }
   ],
   "execution_count": 135
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kjhkK9QFQELu"
   },
   "source": [
    "### Experiments\n",
    "\n",
    "Run experiments on the data. Adjust parameters based on the validation set without using the test set. Your goal is to configure the network so that the quality of the model according to the F1-macro measure on the validation and test sets is no less than **0.76**.\n",
    "\n",
    "Draw conclusions about model quality, overfitting, and sensitivity of the architecture to the choice of hyperparameters. Present the results of your experiments in the form of a mini-report (in the same ipython notebook)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "f4hdrFZ9iRPi",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:36.912067Z",
     "start_time": "2024-11-13T15:29:36.906800Z"
    }
   },
   "source": [
    "# let's create a SummaryWriter for experimenting with BiLSTMModel\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(log_dir=f\"logs/BiLSTMModel\")"
   ],
   "outputs": [],
   "execution_count": 136
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ruMTBSkQQELx"
   },
   "source": [
    "**Exercise. Implement a metric calculation function `compute_metrics`.** **<font color='red'>(1 point)</font>**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xkpo3JgWQELx",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:37.104111Z",
     "start_time": "2024-11-13T15:29:37.070075Z"
    }
   },
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "def compute_metrics(\n",
    "    outputs: torch.Tensor,\n",
    "    labels: torch.LongTensor,\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Compute NER metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    metrics = {}\n",
    "    \n",
    "    outputs = outputs.argmax(dim=1)\n",
    "    mask = labels != -1\n",
    "\n",
    "    # YOUR CODE HERE TODO\n",
    "    # Don't forget to filter the <PAD> token\n",
    "    y_true = labels[mask].cpu()\n",
    "    y_pred = outputs[mask].cpu()\n",
    "    \n",
    "    # accuracy\n",
    "    accuracy = accuracy_score(\n",
    "        y_true=y_true,\n",
    "        y_pred=y_pred,\n",
    "    )\n",
    "\n",
    "    # precision\n",
    "    precision_micro = precision_score(\n",
    "        y_true=y_true,\n",
    "        y_pred=y_pred,\n",
    "        average=\"micro\",\n",
    "        zero_division=0,\n",
    "    )\n",
    "    precision_macro = precision_score(\n",
    "        y_true=y_true,\n",
    "        y_pred=y_pred,\n",
    "        average=\"macro\",\n",
    "        zero_division=0,\n",
    "    )\n",
    "    precision_weighted = precision_score(\n",
    "        y_true=y_true,\n",
    "        y_pred=y_pred,\n",
    "        average=\"weighted\",\n",
    "        zero_division=0,\n",
    "    )\n",
    "\n",
    "    # recall\n",
    "    recall_micro = recall_score(\n",
    "        y_true=y_true,\n",
    "        y_pred=y_pred,\n",
    "        average=\"micro\",\n",
    "        zero_division=0,\n",
    "\n",
    "    )\n",
    "    recall_macro = recall_score(\n",
    "        y_true=y_true,\n",
    "        y_pred=y_pred,\n",
    "        average=\"macro\",\n",
    "        zero_division=0,\n",
    "    )\n",
    "    recall_weighted = recall_score(\n",
    "        y_true=y_true,\n",
    "        y_pred=y_pred,\n",
    "        average=\"weighted\",\n",
    "        zero_division=0,\n",
    "    )\n",
    "\n",
    "    # f1\n",
    "    f1_micro = f1_score(\n",
    "        y_true=y_true,\n",
    "        y_pred=y_pred,\n",
    "        average=\"micro\",\n",
    "        zero_division=0,\n",
    "    )\n",
    "    f1_macro = f1_score(\n",
    "        y_true=y_true,\n",
    "        y_pred=y_pred,\n",
    "        average=\"macro\",\n",
    "        zero_division=0,\n",
    "    )\n",
    "    f1_weighted = f1_score(\n",
    "        y_true=y_true,\n",
    "        y_pred=y_pred,\n",
    "        average=\"weighted\",\n",
    "        zero_division=0,\n",
    "    )\n",
    "\n",
    "    metrics[\"accuracy\"] = accuracy\n",
    "\n",
    "    metrics[\"precision_micro\"]    = precision_micro\n",
    "    metrics[\"precision_macro\"]    = precision_macro\n",
    "    metrics[\"precision_weighted\"] = precision_weighted\n",
    "\n",
    "    metrics[\"recall_micro\"]    = recall_micro\n",
    "    metrics[\"recall_macro\"]    = recall_macro\n",
    "    metrics[\"recall_weighted\"] = recall_weighted\n",
    "\n",
    "    metrics[\"f1_micro\"]    = f1_micro\n",
    "    metrics[\"f1_macro\"]    = f1_macro\n",
    "    metrics[\"f1_weighted\"] = f1_weighted\n",
    "\n",
    "    return metrics"
   ],
   "outputs": [],
   "execution_count": 137
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dzj89UygQEL0"
   },
   "source": [
    "**Exercise. Implement the training and testing functions `train_epoch` and `evaluate_epoch`. <font color='red'>(2 points)</font>**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sG3vQbc_QEL0",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:37.252467Z",
     "start_time": "2024-11-13T15:29:37.243113Z"
    }
   },
   "source": [
    "def train_epoch(\n",
    "    model: torch.nn.Module,\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    criterion: torch.nn.Module,\n",
    "    writer: SummaryWriter,\n",
    "    device: torch.device,\n",
    "    epoch: int,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    One training cycle (loop).\n",
    "    \"\"\"\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = []\n",
    "    batch_metrics_list = defaultdict(list)\n",
    "\n",
    "    for i, (tokens, labels) in tqdm(\n",
    "        enumerate(dataloader),\n",
    "        total=len(dataloader),\n",
    "        desc=\"loop over train batches\",\n",
    "    ):\n",
    "\n",
    "        tokens, labels = tokens.to(device), labels.to(device)\n",
    "        \n",
    "        # Loss calculation and optimizer step\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model.forward(tokens)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss.append(loss.item())\n",
    "        writer.add_scalar(\n",
    "            \"batch loss / train\", loss.item(), epoch * len(dataloader) + i\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            outputs_inference = model(tokens)\n",
    "            model.train()\n",
    "\n",
    "        batch_metrics = compute_metrics(\n",
    "            outputs=outputs_inference,\n",
    "            labels=labels,\n",
    "        )\n",
    "\n",
    "        for metric_name, metric_value in batch_metrics.items():\n",
    "            batch_metrics_list[metric_name].append(metric_value)\n",
    "            writer.add_scalar(\n",
    "                f\"batch {metric_name} / train\",\n",
    "                metric_value,\n",
    "                epoch * len(dataloader) + i,\n",
    "            )\n",
    "\n",
    "    avg_loss = np.mean(epoch_loss)\n",
    "    print(f\"Train loss: {avg_loss}\\n\")\n",
    "    writer.add_scalar(\"loss / train\", avg_loss, epoch)\n",
    "\n",
    "    for metric_name, metric_value_list in batch_metrics_list.items():\n",
    "        metric_value = np.mean(metric_value_list)\n",
    "        print(f\"Train {metric_name}: {metric_value}\\n\")\n",
    "        writer.add_scalar(f\"{metric_name} / train\", metric_value, epoch)"
   ],
   "outputs": [],
   "execution_count": 138
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "p4ztFogtQEL0",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:37.417158Z",
     "start_time": "2024-11-13T15:29:37.393435Z"
    }
   },
   "source": [
    "def evaluate_epoch(\n",
    "    model: torch.nn.Module,\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    "    criterion: torch.nn.Module,\n",
    "    writer: SummaryWriter,\n",
    "    device: torch.device,\n",
    "    epoch: int,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    One evaluation cycle (loop).\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = []\n",
    "    batch_metrics_list = defaultdict(list)\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i, (tokens, labels) in tqdm(\n",
    "            enumerate(dataloader),\n",
    "            total=len(dataloader),\n",
    "            desc=\"loop over test batches\",\n",
    "        ):\n",
    "\n",
    "            tokens, labels = tokens.to(device), labels.to(device)\n",
    "\n",
    "            # Loss calculation\n",
    "            outputs = model.forward(tokens)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            epoch_loss.append(loss.item())\n",
    "            writer.add_scalar(\n",
    "                \"batch loss / test\", loss.item(), epoch * len(dataloader) + i\n",
    "            )\n",
    "\n",
    "            batch_metrics = compute_metrics(\n",
    "                outputs=outputs,\n",
    "                labels=labels,\n",
    "            )\n",
    "\n",
    "            for metric_name, metric_value in batch_metrics.items():\n",
    "                batch_metrics_list[metric_name].append(metric_value)\n",
    "                writer.add_scalar(\n",
    "                    f\"batch {metric_name} / test\",\n",
    "                    metric_value,\n",
    "                    epoch * len(dataloader) + i,\n",
    "                )\n",
    "\n",
    "        avg_loss = np.mean(epoch_loss)\n",
    "        print(f\"Test loss:  {avg_loss}\\n\")\n",
    "        writer.add_scalar(\"loss / test\", avg_loss, epoch)\n",
    "\n",
    "        for metric_name, metric_value_list in batch_metrics_list.items():\n",
    "            metric_value = np.mean(metric_value_list)\n",
    "            print(f\"Test {metric_name}: {metric_value}\\n\")\n",
    "            writer.add_scalar(f\"{metric_name} / test\", np.mean(metric_value), epoch)"
   ],
   "outputs": [],
   "execution_count": 139
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "z7Z5MTNzQEL1",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:29:37.585964Z",
     "start_time": "2024-11-13T15:29:37.542609Z"
    }
   },
   "source": [
    "def train(\n",
    "    n_epochs: int,\n",
    "    model: torch.nn.Module,\n",
    "    train_dataloader: torch.utils.data.DataLoader,\n",
    "    test_dataloader: torch.utils.data.DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    criterion: torch.nn.Module,\n",
    "    writer: SummaryWriter,\n",
    "    device: torch.device,\n",
    "    eval_period: int = 1,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Training loop.\n",
    "    \"\"\"\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        print(f\"Epoch [{epoch+1} / {n_epochs}]\\n\")\n",
    "\n",
    "        train_epoch(\n",
    "            model=model,\n",
    "            dataloader=train_dataloader,\n",
    "            optimizer=optimizer,\n",
    "            criterion=criterion,\n",
    "            writer=writer,\n",
    "            device=device,\n",
    "            epoch=epoch,\n",
    "        )\n",
    "        if eval_period == 1 or epoch != 0 and epoch % eval_period == 0 or epoch == n_epochs - 1:\n",
    "            evaluate_epoch(\n",
    "                model=model,\n",
    "                dataloader=test_dataloader,\n",
    "                criterion=criterion,\n",
    "                writer=writer,\n",
    "                device=device,\n",
    "                epoch=epoch,\n",
    "            )"
   ],
   "outputs": [],
   "execution_count": 140
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTxfU0BfQEL1"
   },
   "source": [
    "**Exercise. Conduct experiments. <font color='red'>(2 points)</font>**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yz6mjGZUQEL2",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:35:26.542031Z",
     "start_time": "2024-11-13T15:30:06.899197Z"
    }
   },
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=50,\n",
    "    shuffle=True,\n",
    "    collate_fn=collator,\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    collate_fn=collator,\n",
    ")\n",
    "\n",
    "model = BiLSTM(\n",
    "    num_embeddings=len(token2idx),\n",
    "    embedding_dim=100,\n",
    "    hidden_size=100,\n",
    "    num_layers=2,\n",
    "    dropout=0.0,\n",
    "    bidirectional=True,\n",
    "    n_classes=len(label2idx),\n",
    ").to(device)\n",
    "writer = SummaryWriter(log_dir=f\"logs/BiLSTMModel\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
    "train(5, model, train_dataloader, test_dataloader, optimizer, criterion, writer, device, eval_period=1)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1 / 5]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop over train batches: 100%|██████████| 300/300 [00:12<00:00, 24.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.618713159263134\n",
      "\n",
      "Train accuracy: 0.8540943613425274\n",
      "\n",
      "Train precision_micro: 0.8540943613425274\n",
      "\n",
      "Train precision_macro: 0.30276129732484625\n",
      "\n",
      "Train precision_weighted: 0.7727601216933763\n",
      "\n",
      "Train recall_micro: 0.8540943613425274\n",
      "\n",
      "Train recall_macro: 0.20990125588463915\n",
      "\n",
      "Train recall_weighted: 0.8540943613425274\n",
      "\n",
      "Train f1_micro: 0.8540943613425274\n",
      "\n",
      "Train f1_macro: 0.2257408838418417\n",
      "\n",
      "Train f1_weighted: 0.8013472341289612\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop over test batches: 100%|██████████| 3683/3683 [00:52<00:00, 70.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  0.4477899064903003\n",
      "\n",
      "Test accuracy: 0.8692069005979718\n",
      "\n",
      "Test precision_micro: 0.8692069005979718\n",
      "\n",
      "Test precision_macro: 0.6584538429562138\n",
      "\n",
      "Test precision_weighted: 0.8247358664530526\n",
      "\n",
      "Test recall_micro: 0.8692069005979718\n",
      "\n",
      "Test recall_macro: 0.6789678995588228\n",
      "\n",
      "Test recall_weighted: 0.8692069005979718\n",
      "\n",
      "Test f1_micro: 0.8692069005979718\n",
      "\n",
      "Test f1_macro: 0.6612050731435178\n",
      "\n",
      "Test f1_weighted: 0.8390781811552914\n",
      "\n",
      "Epoch [2 / 5]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop over train batches: 100%|██████████| 300/300 [00:11<00:00, 25.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.25097804891566433\n",
      "\n",
      "Train accuracy: 0.9301465636116321\n",
      "\n",
      "Train precision_micro: 0.9301465636116321\n",
      "\n",
      "Train precision_macro: 0.7636945154138495\n",
      "\n",
      "Train precision_weighted: 0.9247920879726524\n",
      "\n",
      "Train recall_micro: 0.9301465636116321\n",
      "\n",
      "Train recall_macro: 0.6253741072151899\n",
      "\n",
      "Train recall_weighted: 0.9301465636116321\n",
      "\n",
      "Train f1_micro: 0.9301465636116321\n",
      "\n",
      "Train f1_macro: 0.6650849844791329\n",
      "\n",
      "Train f1_weighted: 0.9228089054011074\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop over test batches: 100%|██████████| 3683/3683 [00:51<00:00, 71.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  0.30208325617901294\n",
      "\n",
      "Test accuracy: 0.9103569041557942\n",
      "\n",
      "Test precision_micro: 0.9103569041557942\n",
      "\n",
      "Test precision_macro: 0.772532385916472\n",
      "\n",
      "Test precision_weighted: 0.8922305617457318\n",
      "\n",
      "Test recall_micro: 0.9103569041557942\n",
      "\n",
      "Test recall_macro: 0.7776788886857227\n",
      "\n",
      "Test recall_weighted: 0.9103569041557942\n",
      "\n",
      "Test f1_micro: 0.9103569041557942\n",
      "\n",
      "Test f1_macro: 0.7694805082176382\n",
      "\n",
      "Test f1_weighted: 0.8961550218016764\n",
      "\n",
      "Epoch [3 / 5]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop over train batches: 100%|██████████| 300/300 [00:12<00:00, 24.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.13810714482019346\n",
      "\n",
      "Train accuracy: 0.9631377464315688\n",
      "\n",
      "Train precision_micro: 0.9631377464315688\n",
      "\n",
      "Train precision_macro: 0.8731911782122127\n",
      "\n",
      "Train precision_weighted: 0.9631793329389643\n",
      "\n",
      "Train recall_micro: 0.9631377464315688\n",
      "\n",
      "Train recall_macro: 0.8090636536034771\n",
      "\n",
      "Train recall_weighted: 0.9631377464315688\n",
      "\n",
      "Train f1_micro: 0.9631377464315688\n",
      "\n",
      "Train f1_macro: 0.8281859127016111\n",
      "\n",
      "Train f1_weighted: 0.9615098729850495\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop over test batches: 100%|██████████| 3683/3683 [00:51<00:00, 71.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  0.2912164108950435\n",
      "\n",
      "Test accuracy: 0.9110859203068519\n",
      "\n",
      "Test precision_micro: 0.9110859203068519\n",
      "\n",
      "Test precision_macro: 0.7886913206057127\n",
      "\n",
      "Test precision_weighted: 0.9028544530641106\n",
      "\n",
      "Test recall_micro: 0.9110859203068519\n",
      "\n",
      "Test recall_macro: 0.7896424598076893\n",
      "\n",
      "Test recall_weighted: 0.9110859203068519\n",
      "\n",
      "Test f1_micro: 0.9110859203068519\n",
      "\n",
      "Test f1_macro: 0.7833178646195499\n",
      "\n",
      "Test f1_weighted: 0.9020498127609006\n",
      "\n",
      "Epoch [4 / 5]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop over train batches: 100%|██████████| 300/300 [00:11<00:00, 25.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.08280609607696533\n",
      "\n",
      "Train accuracy: 0.9794993446884221\n",
      "\n",
      "Train precision_micro: 0.9794993446884221\n",
      "\n",
      "Train precision_macro: 0.9314613904754974\n",
      "\n",
      "Train precision_weighted: 0.9798930870987289\n",
      "\n",
      "Train recall_micro: 0.9794993446884221\n",
      "\n",
      "Train recall_macro: 0.8951564565462968\n",
      "\n",
      "Train recall_weighted: 0.9794993446884221\n",
      "\n",
      "Train f1_micro: 0.9794993446884221\n",
      "\n",
      "Train f1_macro: 0.9059566640178601\n",
      "\n",
      "Train f1_weighted: 0.9789138883032152\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop over test batches: 100%|██████████| 3683/3683 [00:51<00:00, 71.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  0.29146824920505054\n",
      "\n",
      "Test accuracy: 0.9113490750094839\n",
      "\n",
      "Test precision_micro: 0.9113490750094839\n",
      "\n",
      "Test precision_macro: 0.7913686435385172\n",
      "\n",
      "Test precision_weighted: 0.923375266227986\n",
      "\n",
      "Test recall_micro: 0.9113490750094839\n",
      "\n",
      "Test recall_macro: 0.788279199885201\n",
      "\n",
      "Test recall_weighted: 0.9113490750094839\n",
      "\n",
      "Test f1_micro: 0.9113490750094839\n",
      "\n",
      "Test f1_macro: 0.7844562363919\n",
      "\n",
      "Test f1_weighted: 0.9122069284429111\n",
      "\n",
      "Epoch [5 / 5]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop over train batches: 100%|██████████| 300/300 [00:12<00:00, 23.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.05120561507840951\n",
      "\n",
      "Train accuracy: 0.9882850707387839\n",
      "\n",
      "Train precision_micro: 0.9882850707387839\n",
      "\n",
      "Train precision_macro: 0.9580792730675841\n",
      "\n",
      "Train precision_weighted: 0.9886270416184529\n",
      "\n",
      "Train recall_micro: 0.9882850707387839\n",
      "\n",
      "Train recall_macro: 0.9365413895994812\n",
      "\n",
      "Train recall_weighted: 0.9882850707387839\n",
      "\n",
      "Train f1_micro: 0.9882850707387839\n",
      "\n",
      "Train f1_macro: 0.9434020366483925\n",
      "\n",
      "Train f1_weighted: 0.9880528663623329\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop over test batches: 100%|██████████| 3683/3683 [00:50<00:00, 72.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  0.2837645030205308\n",
      "\n",
      "Test accuracy: 0.9170345376495916\n",
      "\n",
      "Test precision_micro: 0.9170345376495916\n",
      "\n",
      "Test precision_macro: 0.8041912361737188\n",
      "\n",
      "Test precision_weighted: 0.9222604831726753\n",
      "\n",
      "Test recall_micro: 0.9170345376495916\n",
      "\n",
      "Test recall_macro: 0.8039598294264774\n",
      "\n",
      "Test recall_weighted: 0.9170345376495916\n",
      "\n",
      "Test f1_micro: 0.9170345376495916\n",
      "\n",
      "Test f1_macro: 0.7989890890855159\n",
      "\n",
      "Test f1_weighted: 0.9153768388403711\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 141
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Report\n",
    "\n",
    "Model quickly achieves the required quality. Apparently, model quality is not sensitive to the choice of hyperparameters. I have not changed anything except of batch size for train dataloader and learning rate. Learning rate was made bigger in order to compensate the increase in batch size. Batch size was increased in order to make the computations faster. Even though with smaller batches final quality of the model may be better, bigger batches allows to make learning process much faster. Model does not show the signs of overfitting, so dropout may be zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H8R6nopyQEL-"
   },
   "source": [
    "## Part 3. Transformers tagger (6 points)\n",
    "\n",
    "In this part of the task, you need to do the same thing, but using a model based on the Transformer architecture, namely, it is proposed to additionally fine-tune the pre-trained **BERT** model.\n",
    "\n",
    "This model requires special data preparation, which is where we will start:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SrbX5gFDQEL-"
   },
   "source": [
    "The **BERT** model uses a custom WordPiece tokenizer to break sentences into tokens. A pre-trained version of such a tokenizer exists in the `transformers` library. There are two classes: `BertTokenizer` and `BertTokenizerFast`. You can use either one, but the second option works much faster because it is written in C programming language.\n",
    "\n",
    "Tokenizers can be trained from scratch using your own data corpus, or you can load pre-trained ones. Pre-trained tokenizers typically match a pre-trained model configuration that uses the vocabulary from that tokenizer.\n",
    "\n",
    "We will use a basic pretrained **BERT** configuration for the model and tokenizer.\n",
    "\n",
    "P.S. Often you have to experiment with models of different architectures, for example **BERT** and **GPT**, so it is convenient to use the `AutoTokenizer` class, which, based on the name of the model, will determine which class is needed to initialize the tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4-UTiI4gQEL-",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:10:16.787699Z",
     "start_time": "2024-11-13T15:10:16.263916Z"
    }
   },
   "source": [
    "from transformers import AutoTokenizer"
   ],
   "outputs": [],
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kSbBhvnDQEMA",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:10:17.044188Z",
     "start_time": "2024-11-13T15:10:17.041576Z"
    }
   },
   "source": [
    "model_name = \"distilbert-base-cased\""
   ],
   "outputs": [],
   "execution_count": 52
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxWNX5i6QEMA"
   },
   "source": [
    "Pretrained models and tokenizers are loaded from `huggingface` using the `from_pretrained` constructor.\n",
    "\n",
    "In this constructor, you can specify either the path to the pretrained tokenizer, or the name of the pretrained configuration, as in our case. `transformers` will load the necessary parameters itself:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3tg_bCeaQEMA",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:10:17.568278Z",
     "start_time": "2024-11-13T15:10:17.144330Z"
    }
   },
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ],
   "outputs": [],
   "execution_count": 53
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MIrbmNoQEMA"
   },
   "source": [
    "### Preparing dictionaries\n",
    "\n",
    "Compared to recurrent models, there is no more need to build a dictionary, since this is already done in advance thanks to tokenizers and the algorithms behind them.\n",
    "\n",
    "But as before, we will need:\n",
    "- {**label**}→{**label_idx**}: correspondence between tag and unique index (starts from 0);\n",
    "\n",
    "We have already implemented this mapping in one of the previous parts of the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CvYF-4uaQEMB"
   },
   "source": [
    "### Preparing the dataset and loader\n",
    "\n",
    "We also want to train the model in batches, so we will still need `Dataset`, `Collator` and `DataLoader`.\n",
    "\n",
    "But we cannot reuse those from the previous parts of the task, since the data processing must be done a little differently using a tokenizer.\n",
    "\n",
    "Let's write a new custom dataset that will receive as input (the `__init__` method):\n",
    "- token_seq - list of lists of words/tokens\n",
    "- label_seq - list of lists of tags\n",
    "\n",
    "and return two lists from the `__getitem__` method:\n",
    "- list of text values (`List[str]`) from token indices in the sample\n",
    "- a list of integer values (`List[int]`) from the indices of the corresponding tags\n",
    "\n",
    "P.S. Unlike the previous custom dataset, here we return two `Lists` instead of `torch.LongTensor`, since we will transfer the logic for generating a padded batch to `Collator` due to the specifics of the tokenizer - it itself returns an already padded tensor with token indexes, and for tag indexes we will need to do this ourselves, similar to the previous dataset.\n",
    "\n",
    "**Exercise. Implement the TransformersDataset class. <font color='red'>(1 point)</font>**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7EoNLDOOQEMB",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:10:17.691485Z",
     "start_time": "2024-11-13T15:10:17.683791Z"
    }
   },
   "source": [
    "class TransformersDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Transformers Dataset for NER.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        token_seq: List[List[str]],\n",
    "        label_seq: List[List[str]],\n",
    "    ):\n",
    "        self.token_seq = token_seq\n",
    "        self.label_seq = [self.process_labels(labels, label2idx) for labels in label_seq]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.token_seq)\n",
    "\n",
    "    def __getitem__(\n",
    "        self,\n",
    "        idx: int,\n",
    "    ) -> Tuple[List[str], List[int]]:\n",
    "         return self.token_seq[idx], self.label_seq[idx]\n",
    "\n",
    "    @staticmethod\n",
    "    def process_labels(\n",
    "        labels: List[str],\n",
    "        label2idx: Dict[str, int],\n",
    "    ) -> List[int]:\n",
    "        \"\"\"\n",
    "        Transform list of labels into list of labels' indices.\n",
    "        \"\"\"\n",
    "        processed_labels = []\n",
    "        for label in labels:\n",
    "            processed_labels.append(label2idx[label])\n",
    "        return processed_labels"
   ],
   "outputs": [],
   "execution_count": 54
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p1oNc-31QEMB"
   },
   "source": [
    "Create three datasets:\n",
    "- *train_dataset*\n",
    "- *valid_dataset*\n",
    "- *test_dataset*"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vqg56Jf8QEMC",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:10:17.890599Z",
     "start_time": "2024-11-13T15:10:17.854892Z"
    }
   },
   "source": [
    "train_dataset = TransformersDataset(\n",
    "    token_seq=train_token_seq,\n",
    "    label_seq=train_label_seq,\n",
    ")\n",
    "valid_dataset = TransformersDataset(\n",
    "    token_seq=valid_token_seq,\n",
    "    label_seq=valid_label_seq,\n",
    ")\n",
    "test_dataset = TransformersDataset(\n",
    "    token_seq=test_token_seq,\n",
    "    label_seq=test_label_seq,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 55
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WdIS6XrvQEMC"
   },
   "source": [
    "Let's look at what we got:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IT00Pjy6QEMC",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:10:18.026310Z",
     "start_time": "2024-11-13T15:10:18.021625Z"
    }
   },
   "source": [
    "train_dataset[0]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['eu', 'rejects', 'german', 'call', 'to', 'boycott', 'british', 'lamb', '.'],\n",
       " [3, 0, 2, 0, 0, 0, 2, 0, 0])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uYal2icQmuD-",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:10:18.277426Z",
     "start_time": "2024-11-13T15:10:18.272518Z"
    }
   },
   "source": [
    "valid_dataset[0]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['cricket',\n",
       "  '-',\n",
       "  'leicestershire',\n",
       "  'take',\n",
       "  'over',\n",
       "  'at',\n",
       "  'top',\n",
       "  'after',\n",
       "  'innings',\n",
       "  'victory',\n",
       "  '.'],\n",
       " [0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FCXd3FWVmuKe",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:10:18.439841Z",
     "start_time": "2024-11-13T15:10:18.434848Z"
    }
   },
   "source": [
    "test_dataset[0]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['soccer',\n",
       "  '-',\n",
       "  'japan',\n",
       "  'get',\n",
       "  'lucky',\n",
       "  'win',\n",
       "  ',',\n",
       "  'china',\n",
       "  'in',\n",
       "  'surprise',\n",
       "  'defeat',\n",
       "  '.'],\n",
       " [0, 0, 1, 0, 0, 0, 0, 4, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "B4R605vAnYT9",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:10:18.573908Z",
     "start_time": "2024-11-13T15:10:18.566449Z"
    }
   },
   "source": [
    "assert len(train_dataset) == 14986, \"Incorrect train_dataset length\"\n",
    "assert len(valid_dataset) == 3465, \"Incorrect valid_dataset length\"\n",
    "assert len(test_dataset) == 3683, \"Incorrect test_dataset length\"\n",
    "\n",
    "assert train_dataset[0][0] == ['eu', 'rejects', 'german', 'call', 'to', 'boycott', 'british', 'lamb', '.'], \"Malformed train_dataset\"\n",
    "assert train_dataset[0][1] == [3,0,2,0,0,0,2,0,0], \"Malformed train_dataset\"\n",
    "\n",
    "assert valid_dataset[0][0] == ['cricket', '-', 'leicestershire', 'take', 'over', 'at', 'top', 'after', 'innings', 'victory', '.'], \"Malformed valid_dataset\"\n",
    "assert valid_dataset[0][1] == [0,0,3,0,0,0,0,0,0,0,0], \"Malformed valid_dataset\"\n",
    "\n",
    "assert test_dataset[0][0] == ['soccer', '-', 'japan', 'get', 'lucky', 'win', ',', 'china', 'in', 'surprise', 'defeat', '.'], \"Malformed test_dataset\"\n",
    "assert test_dataset[0][1] == [0,0,1,0,0,0,0,4,0,0,0,0], \"Malformed test_dataset\"\n",
    "\n",
    "print(\"All tests passed!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed!\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0zP_6iQnQEMC"
   },
   "source": [
    "Let's implement a new `Collator`.\n",
    "\n",
    "The collator will be initialized with 3 arguments:\n",
    "- tokenizer\n",
    "- tokenizer parameters in the form of a dictionary (then used as `**kwargs`)\n",
    "- special token id for tag sequences (value -1)\n",
    "\n",
    "The `__call__` method takes a batch as input, namely a list of tuples of what is returned from the dataset with `__getitem__` method. In our case, this is a list of tuples of two int64 tensors - `List[Tuple[torch.LongTensor, torch.LongTensor]]`.\n",
    "\n",
    "At the output we want to get two tensors:\n",
    "- Padded word/token indexes\n",
    "- Padded tag indexes\n",
    "\n",
    "**Exercise. Implement the TransformersCollator class. <font color='red'>(2 points)</font>**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BonAp65jQEMD",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:10:18.773452Z",
     "start_time": "2024-11-13T15:10:18.763927Z"
    }
   },
   "source": [
    "from transformers import PreTrainedTokenizer\n",
    "from transformers.tokenization_utils_base import BatchEncoding\n",
    "\n",
    "\n",
    "class TransformersCollator:\n",
    "    \"\"\"\n",
    "    Transformers Collator that handles variable-size sentences.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        tokenizer: PreTrainedTokenizer,\n",
    "        tokenizer_kwargs: Dict[str, Any],\n",
    "        label_padding_value: int,\n",
    "    ):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.tokenizer_kwargs = tokenizer_kwargs\n",
    "\n",
    "        self.label_padding_value = label_padding_value\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        batch: List[Tuple[List[str], List[int]]],\n",
    "    ) -> Tuple[BatchEncoding, torch.LongTensor]:\n",
    "        tokens, labels = zip(*batch)\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        tokens = self.tokenizer(tokens, **self.tokenizer_kwargs)\n",
    "        labels = self.encode_labels(tokens, labels, self.label_padding_value)\n",
    "        \n",
    "        tokens.pop(\"offset_mapping\")\n",
    "\n",
    "        return tokens, labels\n",
    "\n",
    "    @staticmethod\n",
    "    def encode_labels(\n",
    "        tokens: BatchEncoding,\n",
    "        labels: List[List[int]],\n",
    "        label_padding_value: int,\n",
    "    ) -> torch.LongTensor:\n",
    "\n",
    "        encoded_labels = []\n",
    "\n",
    "        for doc_labels, doc_offset in zip(labels, tokens.offset_mapping):\n",
    "\n",
    "            doc_enc_labels = np.ones(len(doc_offset), dtype=int) * label_padding_value\n",
    "            arr_offset = np.array(doc_offset)\n",
    "\n",
    "            doc_enc_labels[(arr_offset[:,0] == 0) & (arr_offset[:,1] != 0)] = doc_labels\n",
    "            encoded_labels.append(doc_enc_labels.tolist())\n",
    "\n",
    "        return torch.LongTensor(encoded_labels)"
   ],
   "outputs": [],
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iC8JkUPnQEMD",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:10:18.946021Z",
     "start_time": "2024-11-13T15:10:18.942366Z"
    }
   },
   "source": [
    "tokenizer_kwargs = {\n",
    "    \"is_split_into_words\":    True,\n",
    "    \"return_offsets_mapping\": True,\n",
    "    \"padding\":                True,\n",
    "    \"truncation\":             True,\n",
    "    \"max_length\":             512,\n",
    "    \"return_tensors\":         \"pt\",\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5sCDaxR6QEMD",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:10:19.129760Z",
     "start_time": "2024-11-13T15:10:19.126270Z"
    }
   },
   "source": [
    "collator = TransformersCollator(\n",
    "    tokenizer=tokenizer,\n",
    "    tokenizer_kwargs=tokenizer_kwargs,\n",
    "    label_padding_value=-1,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 62
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eirev0N_QEMD"
   },
   "source": [
    "Now you're ready to define the loaders:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9JDrLC6pQEME",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:13:18.449509Z",
     "start_time": "2024-11-13T15:13:18.444795Z"
    }
   },
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    collate_fn=collator,\n",
    ")\n",
    "valid_dataloader = torch.utils.data.DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=1,  # for correct metrics measurements leave batch_size=1\n",
    "    shuffle=False, # for correct metrics measurements leave shuffle=False\n",
    "    collate_fn=collator,\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,  # for correct metrics measurements leave batch_size=1\n",
    "    shuffle=False, # for correct metrics measurements leave shuffle=False\n",
    "    collate_fn=collator,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 78
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v3zGjEDHQEME"
   },
   "source": [
    "Let's look at what we got:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KSWcYEAWQEME",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:13:20.016990Z",
     "start_time": "2024-11-13T15:13:19.995661Z"
    }
   },
   "source": [
    "tokens, labels = next(iter(train_dataloader))\n",
    "\n",
    "tokens = tokens.to(device)\n",
    "labels = labels.to(device)"
   ],
   "outputs": [],
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NTcdU1BlQEME",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:13:21.374693Z",
     "start_time": "2024-11-13T15:13:21.365055Z"
    }
   },
   "source": [
    "tokens"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,   172,  9238,  9129, 17512,  1116,  1105,  1266,  1484,  1112,\n",
       "          2157,  2495,  6262,   117,  1150,  3042,  1114,  1679,  3329,  1106,\n",
       "          1246,  1103,  7260,  1111,  1679,  3329,   112,   188,  1710,   117,\n",
       "          1125,  1500,  1172,  1119,  1156,  5397,  1136,  1322, 18649,  1679,\n",
       "          3329,   117,  1133,  1152,  1225,  1136,  1221,  2480,  1119,  1156,\n",
       "          1322, 18649,  1330,  3234,   119,   102],\n",
       "        [  101,   179, 15677,  1144,  1151,  6825,  1118,  2212,  1851,  8485,\n",
       "           117,  7032,  1121, 17599,  7301,  4964,  1884, 15615,   119,  1105,\n",
       "          1835,  1671,  6555,  1884, 15615,   119,  1106,  1103, 27629,  1182,\n",
       "          5491,  1433,   119,   102,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 80
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "p7ZTh97-QEME",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:13:23.422566Z",
     "start_time": "2024-11-13T15:13:23.414635Z"
    }
   },
   "source": [
    "labels"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1,  3, -1,  0,  0, -1,  0,  0,  0,  0,  0,  4, -1,  0,  0,  0,  0,  4,\n",
       "         -1,  0,  0,  0,  0,  0,  4, -1,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0, -1,  4, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,  0,  0,\n",
       "          0, -1],\n",
       "        [-1,  2, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  3, -1, -1,  7, -1,\n",
       "         -1,  0,  3,  7,  7,  7, -1, -1,  0,  0,  1, -1, -1,  0,  0, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1]], device='cuda:0')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 81
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pMprtk9bodM9",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:13:24.814147Z",
     "start_time": "2024-11-13T15:13:24.790672Z"
    }
   },
   "source": [
    "train_tokens, train_labels = next(iter(\n",
    "    torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=2,\n",
    "        shuffle=False,\n",
    "        collate_fn=collator,\n",
    "    )\n",
    "))\n",
    "assert torch.equal(\n",
    "    train_tokens['input_ids'],\n",
    "    torch.tensor([[101, 174, 1358, 22961, 176, 14170, 1840, 1106, 21423, 9304, 10721, 1324, 2495, 12913, 119, 102],\n",
    "                  [101, 11109, 1200, 1602, 6715, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
    "                )), \"Looks like a bug in the collator\"\n",
    "assert torch.equal(\n",
    "    train_tokens['attention_mask'],\n",
    "    torch.tensor([\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    ])), \"Looks like a bug in the collator\"\n",
    "assert torch.equal(\n",
    "    train_labels,\n",
    "    torch.tensor([\n",
    "        [-1, 3, -1, 0, 2, -1, 0, 0, 0, 2, -1, -1, 0, -1, 0, -1],\n",
    "        [-1, 4, -1, 8, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
    "    ])), \"Looks like a bug in the collator\"\n",
    "\n",
    "valid_tokens, valid_labels = next(iter(\n",
    "    torch.utils.data.DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=2,\n",
    "        shuffle=False,\n",
    "        collate_fn=collator,\n",
    "    )\n",
    "))\n",
    "assert torch.equal(\n",
    "    valid_tokens['input_ids'],\n",
    "    torch.tensor([\n",
    "        [101, 5428, 118, 5837, 18117, 5759, 15189, 1321, 1166, 1120, 1499, 1170, 6687, 2681, 119, 102],\n",
    "        [101, 25338, 17996, 1820, 118, 4775, 118, 1476, 102, 0, 0, 0, 0, 0, 0, 0]\n",
    "    ])), \"Looks like a bug in the collator\"\n",
    "assert torch.equal(\n",
    "    valid_tokens['attention_mask'],\n",
    "    torch.tensor([\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "    ])), \"Looks like a bug in the collator\"\n",
    "assert torch.equal(\n",
    "    valid_labels,\n",
    "    torch.tensor([\n",
    "        [-1,  0,  0,  3, -1, -1, -1,  0,  0,  0,  0,  0,  0,  0,  0, -1],\n",
    "        [-1,  1, -1,  0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
    "    ])), \"Looks like a bug in the collator\"\n",
    "\n",
    "test_tokens, test_labels = next(iter(\n",
    "    torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=2,\n",
    "        shuffle=False,\n",
    "        collate_fn=collator,\n",
    "    )\n",
    "))\n",
    "assert torch.equal(\n",
    "    test_tokens['input_ids'],\n",
    "    torch.tensor([\n",
    "        [101, 5862, 118, 179, 26519, 1179, 1243, 6918, 1782, 117, 5144, 1161, 1107, 3774, 3326, 119, 102],\n",
    "        [101, 9468, 3309, 1306, 19122, 2293, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    ])), \"Looks like a bug in the collator\"\n",
    "assert torch.equal(\n",
    "    test_tokens['attention_mask'],\n",
    "    torch.tensor([\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    ])), \"Looks like a bug in the collator\"\n",
    "assert torch.equal(\n",
    "    test_labels,\n",
    "    torch.tensor([\n",
    "        [-1,  0,  0,  1, -1, -1,  0,  0,  0,  0,  4, -1,  0,  0,  0,  0, -1],\n",
    "        [-1,  4, -1, -1,  8, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
    "    ])), \"Looks like a bug in the collator\"\n",
    "\n",
    "print(\"All tests passed!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed!\n"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_m-taH0SQEMF"
   },
   "source": [
    "The **transformers** library contains classes for the BERT model, already customized to solve specific problems, with corresponding classification heads. For the NER task we will use the `BertForTokenClassification` class.\n",
    "\n",
    "By analogy with tokenizers, we can use the `AutoModelForTokenClassification` class, which, based on the name of the model, will determine which class is needed to initialize the model."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "x6tq_i7JQEMF",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:13:28.928818Z",
     "start_time": "2024-11-13T15:13:28.925698Z"
    }
   },
   "source": [
    "from transformers import AutoModelForTokenClassification"
   ],
   "outputs": [],
   "execution_count": 83
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Vma9yj0zQEMF",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:13:30.646951Z",
     "start_time": "2024-11-13T15:13:30.340501Z"
    }
   },
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(label2idx),\n",
    ").to(device)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 84
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Imv-6gAQQEMG",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:13:32.646879Z",
     "start_time": "2024-11-13T15:13:32.643620Z"
    }
   },
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)"
   ],
   "outputs": [],
   "execution_count": 85
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LAdHfn4oQEMG",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:13:34.062715Z",
     "start_time": "2024-11-13T15:13:34.051537Z"
    }
   },
   "source": [
    "outputs = model(**tokens)"
   ],
   "outputs": [],
   "execution_count": 86
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "P-kTke_8QEMG",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:13:35.619017Z",
     "start_time": "2024-11-13T15:13:35.614557Z"
    }
   },
   "source": [
    "assert 2 < criterion(outputs[\"logits\"].transpose(1, 2), labels) < 3\n",
    "\n",
    "print(\"All tests passed!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed!\n"
     ]
    }
   ],
   "execution_count": 87
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5Ana4qGKeHrN",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:13:38.571129Z",
     "start_time": "2024-11-13T15:13:38.563939Z"
    }
   },
   "source": [
    "# let's create a SummaryWriter for experimenting with BiLSTMModel\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(log_dir=f\"logs/Transformer\")"
   ],
   "outputs": [],
   "execution_count": 88
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8sNuFPRdQEMH"
   },
   "source": [
    "### Experiments\n",
    "\n",
    "Run experiments on the data. Adjust parameters based on the validation set without using the test set. Your goal is to configure the network so that the quality of the model according to the F1-macro measure on the validation and test sets is no less than **0.9**.\n",
    "\n",
    "Draw conclusions about model quality, overfitting, and sensitivity of the architecture to the choice of hyperparameters. Present the results of your experiments in the form of a mini-report (in the same ipython notebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7IfkN20lrN0J"
   },
   "source": [
    "You can use the same train function as before, except that instead of `model(tokens)` inference you need to do `model(**tokens)`, and instead of `outputs` you use `outputs[\"logits\"].transpose(1, 2)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8iyZUFddzYE5"
   },
   "source": [
    "**Exercise. Conduct experiments.** **<font color='red'>(2 points)</font>**"
   ]
  },
  {
   "metadata": {
    "id": "sG3vQbc_QEL0",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:13:44.912520Z",
     "start_time": "2024-11-13T15:13:44.901501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_epoch_trans(\n",
    "    model: torch.nn.Module,\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    criterion: torch.nn.Module,\n",
    "    writer: SummaryWriter,\n",
    "    device: torch.device,\n",
    "    epoch: int,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    One training cycle (loop).\n",
    "    \"\"\"\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = []\n",
    "    batch_metrics_list = defaultdict(list)\n",
    "\n",
    "    for i, (tokens, labels) in tqdm(\n",
    "        enumerate(dataloader),\n",
    "        total=len(dataloader),\n",
    "        desc=\"loop over train batches\",\n",
    "    ):\n",
    "\n",
    "        tokens, labels = tokens.to(device), labels.to(device)\n",
    "        \n",
    "        # Loss calculation and optimizer step\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model.forward(**tokens)[\"logits\"].transpose(1, 2)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss.append(loss.item())\n",
    "        writer.add_scalar(\n",
    "            \"batch loss / train\", loss.item(), epoch * len(dataloader) + i\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            outputs_inference = model(**tokens)[\"logits\"].transpose(1, 2)\n",
    "            model.train()\n",
    "\n",
    "        batch_metrics = compute_metrics(\n",
    "            outputs=outputs_inference,\n",
    "            labels=labels,\n",
    "        )\n",
    "\n",
    "        for metric_name, metric_value in batch_metrics.items():\n",
    "            batch_metrics_list[metric_name].append(metric_value)\n",
    "            writer.add_scalar(\n",
    "                f\"batch {metric_name} / train\",\n",
    "                metric_value,\n",
    "                epoch * len(dataloader) + i,\n",
    "            )\n",
    "\n",
    "    avg_loss = np.mean(epoch_loss)\n",
    "    print(f\"Train loss: {avg_loss}\\n\")\n",
    "    writer.add_scalar(\"loss / train\", avg_loss, epoch)\n",
    "\n",
    "    for metric_name, metric_value_list in batch_metrics_list.items():\n",
    "        metric_value = np.mean(metric_value_list)\n",
    "        print(f\"Train {metric_name}: {metric_value}\\n\")\n",
    "        writer.add_scalar(f\"{metric_name} / train\", metric_value, epoch)"
   ],
   "outputs": [],
   "execution_count": 89
  },
  {
   "metadata": {
    "id": "p4ztFogtQEL0",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:13:45.018257Z",
     "start_time": "2024-11-13T15:13:45.009369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_epoch_trans(\n",
    "    model: torch.nn.Module,\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    "    criterion: torch.nn.Module,\n",
    "    writer: SummaryWriter,\n",
    "    device: torch.device,\n",
    "    epoch: int,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    One evaluation cycle (loop).\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = []\n",
    "    batch_metrics_list = defaultdict(list)\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i, (tokens, labels) in tqdm(\n",
    "            enumerate(dataloader),\n",
    "            total=len(dataloader),\n",
    "            desc=\"loop over test batches\",\n",
    "        ):\n",
    "\n",
    "            tokens, labels = tokens.to(device), labels.to(device)\n",
    "\n",
    "            # Loss calculation\n",
    "            outputs = model.forward(**tokens)[\"logits\"].transpose(1, 2)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            epoch_loss.append(loss.item())\n",
    "            writer.add_scalar(\n",
    "                \"batch loss / test\", loss.item(), epoch * len(dataloader) + i\n",
    "            )\n",
    "\n",
    "            batch_metrics = compute_metrics(\n",
    "                outputs=outputs,\n",
    "                labels=labels,\n",
    "            )\n",
    "\n",
    "            for metric_name, metric_value in batch_metrics.items():\n",
    "                batch_metrics_list[metric_name].append(metric_value)\n",
    "                writer.add_scalar(\n",
    "                    f\"batch {metric_name} / test\",\n",
    "                    metric_value,\n",
    "                    epoch * len(dataloader) + i,\n",
    "                )\n",
    "\n",
    "        avg_loss = np.mean(epoch_loss)\n",
    "        print(f\"Test loss:  {avg_loss}\\n\")\n",
    "        writer.add_scalar(\"loss / test\", avg_loss, epoch)\n",
    "\n",
    "        for metric_name, metric_value_list in batch_metrics_list.items():\n",
    "            metric_value = np.mean(metric_value_list)\n",
    "            print(f\"Test {metric_name}: {metric_value}\\n\")\n",
    "            writer.add_scalar(f\"{metric_name} / test\", np.mean(metric_value), epoch)"
   ],
   "outputs": [],
   "execution_count": 90
  },
  {
   "metadata": {
    "id": "z7Z5MTNzQEL1",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:13:45.356897Z",
     "start_time": "2024-11-13T15:13:45.350856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_trans(\n",
    "    n_epochs: int,\n",
    "    model: torch.nn.Module,\n",
    "    train_dataloader: torch.utils.data.DataLoader,\n",
    "    test_dataloader: torch.utils.data.DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    criterion: torch.nn.Module,\n",
    "    writer: SummaryWriter,\n",
    "    device: torch.device,\n",
    "    eval_period: int = 1,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Training loop.\n",
    "    \"\"\"\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        print(f\"Epoch [{epoch+1} / {n_epochs}]\\n\")\n",
    "\n",
    "        train_epoch_trans(\n",
    "            model=model,\n",
    "            dataloader=train_dataloader,\n",
    "            optimizer=optimizer,\n",
    "            criterion=criterion,\n",
    "            writer=writer,\n",
    "            device=device,\n",
    "            epoch=epoch,\n",
    "        )\n",
    "        if eval_period == 1 or epoch != 0 and epoch % eval_period == 0 or epoch == n_epochs - 1:\n",
    "            evaluate_epoch_trans(\n",
    "                model=model,\n",
    "                dataloader=test_dataloader,\n",
    "                criterion=criterion,\n",
    "                writer=writer,\n",
    "                device=device,\n",
    "                epoch=epoch,\n",
    "            )"
   ],
   "outputs": [],
   "execution_count": 91
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Iv92wK5P7pjl",
    "ExecuteTime": {
     "end_time": "2024-11-13T15:26:59.233196Z",
     "start_time": "2024-11-13T15:13:45.460408Z"
    }
   },
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "collator = TransformersCollator(\n",
    "    tokenizer=tokenizer,\n",
    "    tokenizer_kwargs=tokenizer_kwargs,\n",
    "    label_padding_value=-1,\n",
    ")\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=50,\n",
    "    shuffle=True,\n",
    "    collate_fn=collator,\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,  # for correct metrics measurements leave batch_size=1\n",
    "    shuffle=False, # for correct metrics measurements leave shuffle=False\n",
    "    collate_fn=collator,\n",
    ")\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(label2idx),\n",
    ").to(device)\n",
    "\n",
    "writer = SummaryWriter(log_dir=f\"logs/Transformer\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
    "train_trans(10, model, train_dataloader, test_dataloader, optimizer, criterion, writer, device)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1 / 10]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop over train batches: 100%|██████████| 300/300 [01:29<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.37359702207148077\n",
      "\n",
      "Train accuracy: 0.903700886377743\n",
      "\n",
      "Train precision_micro: 0.903700886377743\n",
      "\n",
      "Train precision_macro: 0.49229754003133425\n",
      "\n",
      "Train precision_weighted: 0.8710750556367649\n",
      "\n",
      "Train recall_micro: 0.903700886377743\n",
      "\n",
      "Train recall_macro: 0.4675347001625073\n",
      "\n",
      "Train recall_weighted: 0.903700886377743\n",
      "\n",
      "Train f1_micro: 0.903700886377743\n",
      "\n",
      "Train f1_macro: 0.4601097466550333\n",
      "\n",
      "Train f1_weighted: 0.8804380840125106\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop over test batches: 100%|██████████| 3683/3683 [01:03<00:00, 58.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  0.15741679780386256\n",
      "\n",
      "Test accuracy: 0.9527539045226862\n",
      "\n",
      "Test precision_micro: 0.9527539045226862\n",
      "\n",
      "Test precision_macro: 0.8779304265277891\n",
      "\n",
      "Test precision_weighted: 0.9569568273846323\n",
      "\n",
      "Test recall_micro: 0.9527539045226862\n",
      "\n",
      "Test recall_macro: 0.8790412129293054\n",
      "\n",
      "Test recall_weighted: 0.9527539045226862\n",
      "\n",
      "Test f1_micro: 0.9527539045226862\n",
      "\n",
      "Test f1_macro: 0.8753078570499775\n",
      "\n",
      "Test f1_weighted: 0.9529108833523321\n",
      "\n",
      "Epoch [2 / 10]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop over train batches: 100%|██████████| 300/300 [01:28<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.08716369304185112\n",
      "\n",
      "Train accuracy: 0.9774116496586484\n",
      "\n",
      "Train precision_micro: 0.9774116496586484\n",
      "\n",
      "Train precision_macro: 0.8880414006928977\n",
      "\n",
      "Train precision_weighted: 0.9781209113708373\n",
      "\n",
      "Train recall_micro: 0.9774116496586484\n",
      "\n",
      "Train recall_macro: 0.868043946550824\n",
      "\n",
      "Train recall_weighted: 0.9774116496586484\n",
      "\n",
      "Train f1_micro: 0.9774116496586484\n",
      "\n",
      "Train f1_macro: 0.8674387171196652\n",
      "\n",
      "Train f1_weighted: 0.9767670588294052\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop over test batches: 100%|██████████| 3683/3683 [01:04<00:00, 57.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  0.14544220132082167\n",
      "\n",
      "Test accuracy: 0.9586749109796373\n",
      "\n",
      "Test precision_micro: 0.9586749109796373\n",
      "\n",
      "Test precision_macro: 0.8911024219821508\n",
      "\n",
      "Test precision_weighted: 0.9615908381632658\n",
      "\n",
      "Test recall_micro: 0.9586749109796373\n",
      "\n",
      "Test recall_macro: 0.8915812799747395\n",
      "\n",
      "Test recall_weighted: 0.9586749109796373\n",
      "\n",
      "Test f1_micro: 0.9586749109796373\n",
      "\n",
      "Test f1_macro: 0.888770768935603\n",
      "\n",
      "Test f1_weighted: 0.9584442864966641\n",
      "\n",
      "Epoch [3 / 10]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop over train batches: 100%|██████████| 300/300 [01:29<00:00,  3.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.056330162640661\n",
      "\n",
      "Train accuracy: 0.9865896076597778\n",
      "\n",
      "Train precision_micro: 0.9865896076597778\n",
      "\n",
      "Train precision_macro: 0.9275980048158885\n",
      "\n",
      "Train precision_weighted: 0.9874692320901869\n",
      "\n",
      "Train recall_micro: 0.9865896076597778\n",
      "\n",
      "Train recall_macro: 0.9228968049145031\n",
      "\n",
      "Train recall_weighted: 0.9865896076597778\n",
      "\n",
      "Train f1_micro: 0.9865896076597778\n",
      "\n",
      "Train f1_macro: 0.9186835974592589\n",
      "\n",
      "Train f1_weighted: 0.9864937654547684\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop over test batches: 100%|██████████| 3683/3683 [01:03<00:00, 58.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  0.15952471500311802\n",
      "\n",
      "Test accuracy: 0.9599912933218697\n",
      "\n",
      "Test precision_micro: 0.9599912933218697\n",
      "\n",
      "Test precision_macro: 0.8998151926811003\n",
      "\n",
      "Test precision_weighted: 0.9679225093488029\n",
      "\n",
      "Test recall_micro: 0.9599912933218697\n",
      "\n",
      "Test recall_macro: 0.8990151466221148\n",
      "\n",
      "Test recall_weighted: 0.9599912933218697\n",
      "\n",
      "Test f1_micro: 0.9599912933218697\n",
      "\n",
      "Test f1_macro: 0.8969413561112791\n",
      "\n",
      "Test f1_weighted: 0.9623129800596857\n",
      "\n",
      "Epoch [4 / 10]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop over train batches: 100%|██████████| 300/300 [01:29<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0394978830528756\n",
      "\n",
      "Train accuracy: 0.9916320533769825\n",
      "\n",
      "Train precision_micro: 0.9916320533769825\n",
      "\n",
      "Train precision_macro: 0.953067619701626\n",
      "\n",
      "Train precision_weighted: 0.9922309136039018\n",
      "\n",
      "Train recall_micro: 0.9916320533769825\n",
      "\n",
      "Train recall_macro: 0.9552561196874042\n",
      "\n",
      "Train recall_weighted: 0.9916320533769825\n",
      "\n",
      "Train f1_micro: 0.9916320533769825\n",
      "\n",
      "Train f1_macro: 0.9502143154411484\n",
      "\n",
      "Train f1_weighted: 0.9916256607716097\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop over test batches: 100%|██████████| 3683/3683 [01:04<00:00, 57.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  0.15110479844481675\n",
      "\n",
      "Test accuracy: 0.964965521925726\n",
      "\n",
      "Test precision_micro: 0.964965521925726\n",
      "\n",
      "Test precision_macro: 0.909744548418788\n",
      "\n",
      "Test precision_weighted: 0.9677796329424537\n",
      "\n",
      "Test recall_micro: 0.964965521925726\n",
      "\n",
      "Test recall_macro: 0.9089062530655475\n",
      "\n",
      "Test recall_weighted: 0.964965521925726\n",
      "\n",
      "Test f1_micro: 0.964965521925726\n",
      "\n",
      "Test f1_macro: 0.9070850343286011\n",
      "\n",
      "Test f1_weighted: 0.9648865187348923\n",
      "\n",
      "Epoch [5 / 10]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop over train batches: 100%|██████████| 300/300 [01:29<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.028272132199878494\n",
      "\n",
      "Train accuracy: 0.9948073728448734\n",
      "\n",
      "Train precision_micro: 0.9948073728448734\n",
      "\n",
      "Train precision_macro: 0.970895138320108\n",
      "\n",
      "Train precision_weighted: 0.9952396291559296\n",
      "\n",
      "Train recall_micro: 0.9948073728448734\n",
      "\n",
      "Train recall_macro: 0.9727026010588758\n",
      "\n",
      "Train recall_weighted: 0.9948073728448734\n",
      "\n",
      "Train f1_micro: 0.9948073728448734\n",
      "\n",
      "Train f1_macro: 0.9693906877593367\n",
      "\n",
      "Train f1_weighted: 0.9948329726206996\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop over test batches: 100%|██████████| 3683/3683 [01:04<00:00, 57.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  0.1640733233094481\n",
      "\n",
      "Test accuracy: 0.9644307144179602\n",
      "\n",
      "Test precision_micro: 0.9644307144179602\n",
      "\n",
      "Test precision_macro: 0.9103068762269049\n",
      "\n",
      "Test precision_weighted: 0.967897868086859\n",
      "\n",
      "Test recall_micro: 0.9644307144179602\n",
      "\n",
      "Test recall_macro: 0.9097354522965331\n",
      "\n",
      "Test recall_weighted: 0.9644307144179602\n",
      "\n",
      "Test f1_micro: 0.9644307144179602\n",
      "\n",
      "Test f1_macro: 0.9078356600660601\n",
      "\n",
      "Test f1_weighted: 0.9646799700393738\n",
      "\n",
      "Epoch [6 / 10]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop over train batches:  31%|███       | 92/300 [00:27<01:01,  3.36it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[92], line 30\u001B[0m\n\u001B[1;32m     28\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-5\u001B[39m)\n\u001B[1;32m     29\u001B[0m criterion \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mCrossEntropyLoss(ignore_index\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m---> 30\u001B[0m \u001B[43mtrain_trans\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwriter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[91], line 20\u001B[0m, in \u001B[0;36mtrain_trans\u001B[0;34m(n_epochs, model, train_dataloader, test_dataloader, optimizer, criterion, writer, device, eval_period)\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_epochs):\n\u001B[1;32m     18\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m / \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mn_epochs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m]\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 20\u001B[0m     \u001B[43mtrain_epoch_trans\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdataloader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     23\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     24\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     25\u001B[0m \u001B[43m        \u001B[49m\u001B[43mwriter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwriter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     26\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     27\u001B[0m \u001B[43m        \u001B[49m\u001B[43mepoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     28\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     29\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m eval_period \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m epoch \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m epoch \u001B[38;5;241m%\u001B[39m eval_period \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m epoch \u001B[38;5;241m==\u001B[39m n_epochs \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m     30\u001B[0m         evaluate_epoch_trans(\n\u001B[1;32m     31\u001B[0m             model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[1;32m     32\u001B[0m             dataloader\u001B[38;5;241m=\u001B[39mtest_dataloader,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     36\u001B[0m             epoch\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m     37\u001B[0m         )\n",
      "Cell \u001B[0;32mIn[89], line 45\u001B[0m, in \u001B[0;36mtrain_epoch_trans\u001B[0;34m(model, dataloader, optimizer, criterion, writer, device, epoch)\u001B[0m\n\u001B[1;32m     42\u001B[0m     outputs_inference \u001B[38;5;241m=\u001B[39m model(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mtokens)[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlogits\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m     43\u001B[0m     model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m---> 45\u001B[0m batch_metrics \u001B[38;5;241m=\u001B[39m \u001B[43mcompute_metrics\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     46\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutputs_inference\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     47\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     48\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m metric_name, metric_value \u001B[38;5;129;01min\u001B[39;00m batch_metrics\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m     51\u001B[0m     batch_metrics_list[metric_name]\u001B[38;5;241m.\u001B[39mappend(metric_value)\n",
      "Cell \u001B[0;32mIn[46], line 19\u001B[0m, in \u001B[0;36mcompute_metrics\u001B[0;34m(outputs, labels)\u001B[0m\n\u001B[1;32m     15\u001B[0m mask \u001B[38;5;241m=\u001B[39m labels \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m# YOUR CODE HERE TODO\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# Don't forget to filter the <PAD> token\u001B[39;00m\n\u001B[0;32m---> 19\u001B[0m y_true \u001B[38;5;241m=\u001B[39m \u001B[43mlabels\u001B[49m\u001B[43m[\u001B[49m\u001B[43mmask\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcpu\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     20\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m outputs[mask]\u001B[38;5;241m.\u001B[39mcpu()\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# accuracy\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 92
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Report\n",
    "\n",
    "It can be seen that model quality significatly increased in comparison with non-transformer model. Apparently, model quality is not sensitive to the choice of hyperparameters. Like with the previous model, I have not changed anything except of batch size for train dataloader. This change was made in order to make the computations faster. Even though with smaller batches final quality of the model may be better, bigger batches allows to make learning process much faster. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5XlI3cb1QEL2"
   },
   "source": [
    "## Part 4 - Bonus. BiLSTMAttention-tagger (2 points)\n",
    "\n",
    "You need to carry out the same experiments as in part 2, but using the improved BiLSTM tagger architecture with the Attention mechanism.\n",
    "\n",
    "**Please note** that you do not need to implement Attention yourself; you can use `torch.nn.MultiheadAttention`.\n",
    "\n",
    "Also draw conclusions about model quality, overfitting, sensitivity of the architecture to the choice of hyperparameters, and do a little comparative analysis with the previous architecture. Present the results of your experiments in the form of a mini-report (in the same ipython notebook).\n",
    "\n",
    "**Exercise. Implement the model class BiLSTMAttn.** **<font color='red'>(1 point)</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_MyLQp047yID"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ezh9kLTkQEL9"
   },
   "source": [
    "**Exercise. Conduct experiments and beat the metric value from part 2.** **<font color='red'>(1 point)</font>**\n",
    "\n",
    "P.S. If quality didn't increase, this needs to be justified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sE1C1tzEQEL-"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "4MIrbmNoQEMA"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "8d4ce941904148077feb793883e611d25d231ca995d9164b22ee99fd0facd8d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
